##第10章　テキストの分類分析
##pp.187-188
##スパムメールのデータセット
install.packages("kernlab")
library(kernlab)
data(spam)
dim(spam)
str(spam)
##変数typeがspamであるかnonspamであるかを示す因子データである．
##学習と予測のプロセスを説明するため，データセットの中から10分の1をランダムに抽出してテストデータとし，それ以外を学習データとする．
m<-round(nrow(spam)/10)     #10分の1の数を計算する．
set.seed(1)                 #乱数の種を指定する．
sp<-sample(1:nrow(spam), m) #標本の行の番号をサンプリングする．
train_data<-spam[-sp, ]     #学習用データを作成する．
test_data<-spam[sp, ]       #テスト用データを作成する．

##knnを用いたスパムメールの分類の例
##kNN法を用いるためにはまずkを指定しなければならない．
##とりあえずk=3で行ってみよう．
install.packages(c("class", "e1071", "caret"))
library(class)
library(e1071)
library(caret)
knn.md1<-knn(train_data[, -58], test_data[, -58],
             train_data[, 58], k=3) 　　  #学習データを用いてテストを行う．
conM<-table(test_data[, 58], knn.md1)　　 #混同表を作成する．
confusionMatrix(conM, mode="prec_recall") #混同表の統計量を返す．

##pp.189
spam[1:2, c(1:3, 54:57)]

##pp.189
##データの標準化と一部変数の削除
##データを標準化して分類を行う
Sdata<-scale(train_data[, -58])
train1<-data.frame(Sdata, type=train_data$type)
Stest<-scale(test_data[, -58])
test1<-data.frame(Stest, type=test_data$type)
knn.md2<-knn(train1[, -58], test1[, -58], train1[, 58], k=3)
conM<-table(test1[, 58], knn.md2)
confusionMatrix(conM, mode="prec_recall")
##変数1~54までを用いて分類を行ってみよう．
knn.md3<-knn(train_data[, 1:54], test_data[, 1:54],
             train_data[, 58], k=3)
conM<-table(test_data[, 58], knn.md3)
confusionMatrix(conM, mode="prec_recall")

##pp.191-193
##train{caret}を用いたk近傍法のkのチューニング
install.packages("caret", dep=TRUE)
library(caret)
##train{caret}を用いてkについてチューニングを行う．
knn.md4<-train(type~., data=train_data,
               method="knn",
               tuneGrid=expand.grid(k=c(1:10)),
               preProcess=c("center", "scale"),
               trControl=trainControl(method="CV", classProbs=TRUE,
                                      summaryFunction=multiClassSummary)
)
##計算された結果はknn.md4に保存され，評価指標の項目は次のコマンドで確認できる．
##knn.md4を実行するとk=1~10の以下に示す指標の値を返し，最後に推奨するkの値を返す．
##このkは正解率（Accuracy）に基づいて判断している．用いたデータではk=1が推奨されている．
knn.md4
plot(knn.md4) #グラフを作成して考察することもできる．
colnames(knn.md4$results)
##主な学習結果を次に返す．
round(knn.md4$results[, c("k", "AUC", "Accuracy", "Kappa", "Precision", "Recall", "F1")], 3)
##テストデータを用いた予測は関数predictを用いる．
pre.knn<-predict(knn.md4, test_data)
conM<-table(test_data[, 58], pre.knn)
confusionMatrix(conM, mode="prec_recall")
##F1はk=1の場合がk=3の場合より高い．

##pp.194-196
##線形判別分析法による分析結果を次に示す．
##方法1：関数lda{MASS}を用いる．
library(MASS)
lda.mod1<-lda(type~., data=train_data)
##作成したモデルの評価指標を確認してみよう．
pre.mod1<-predict(lda.mod1)     　　　　　　　#学習データの判別結果
conM<-table(train_data[, 58], pre.mod1$class) #判別結果の混同表
confusionMatrix(conM, mod="prec_recall")      #混同表の統計量
##学習モデルを用いた予測
pre.mod2<-predict(lda.mod1, test_data)
conM<-table(test_data[, 58], pre.mod2$class)
confusionMatrix(conM, mode="prec_recall")
##方法2：関数train{caret}を用いる．
lda.mod2<-train(type~., data=train_data,
                method="lda",
                preProcess=c("center", "scale"),
                trControl=trainControl(method="CV", classProbs=TRUE,
                                       summaryFunction=multiClassSummary)
)
round(lda.mod2$results[, c("AUC", "Accuracy", "Kappa", "Precision", "Recall", "F1")], 4)
##学習モデルを用いた予測
pre.mod3<-predict(lda.mod2, test_data)
conM<-table(test_data[, 58], pre.mod3)
confusionMatrix(conM, mode="prec_recall")
##結果はlda{MASS}と同じである．

##pp.196-197
##判別関数の係数の棒グラフの作成
##上記の関数trainでは係数を抜き出すことが面倒であるため，lda{MASS}を用いる．
spam.lda2<-lda(type~., data=spam)
##求めた判別関数の係数はspam.lda2$scalingに保存している．
coef1<-spam.lda2$scaling
coef<-coef1[sort.list(coef1, dec=TRUE), ]
par(mar=c(4, 10, 2, 2))
barplot(coef[c(1:15, 43:57)], las=2, horiz=T, cex.names=0.9,
        col=c(rep(3:4, each=15)))
text(-0.5, 10, "スパムメール\nの特徴要素", cex=1.5)
text(-0.5, 25, "ノンスパムメール\nの特徴要素", cex=1.5)

##pp.198-200
##二項ロジスティック回帰・判別の例
##多項ロジスティック判別関数multinom{nnet}を用いる．
##関数multinomには，交差検証法がない．
library(nnet)
set.seed(10)
mu1<-multinom(type~., data=train_data)
coef(mu1)                      #係数を返す
##主な判別係数の棒グラフを作成する
coef1<-sort(coef(mu1)[-1])     #係数を小さい順位に並び替える．
coef2<-coef1[c(1:15, 43:57)]   #上・下位15個を抜き出す．
par(mar=c(4, 10, 2, 2))
barplot(coef2, horiz=T, las=2, col=c(rep(3, 15), rep(4, 15)))
##データの判別
pre.mu1<-predict(mu1)
conM<-table(train_data[, 58], pre.mu1)
confusionMatrix(conM, mode="prec_recall")
##テストデータの判別
pre.mu2<-predict(mu1, test_data)
conM<-table(test_data[, 58], pre.mu2)
confusionMatrix(conM, mode="prec_recall")
##交差検証法を行う場合は，関数trainを用いることができる．
##また，重みを求める際に，値が大きくなりすぎないようなペナルティをかけている．
##このペナルティをどれぐらいにするかはデータに依存する．
##関数trainではこれをチューニングできるように組み込んでいる．
mu2<-train(type~., data=train_data,
           method="multinom",
           preProcess=c("center", "scale"),
           trControl=trainControl(method="CV", classProbs=TRUE,
                                  summaryFunction=multiClassSummary)
)
mu2 #計算結果を返す．
##ペナルティの値はdecay=1e-04を推奨している．
round(mu2$results[, c("decay", "AUC", "Accuracy", "Kappa",
                      "Precision", "Recall", "F1")], 4)
##テストデータを用いた予測は関数predictを用いる
pre.mu2<-predict(mu2, test_data[, -58])
##混同行列および正解率，Kappa係数などを返す
conM<-table(test_data[, 58], pre.mu2)
confusionMatrix(conM, mode="prec_recall")
##kNN法と線形判別より，正解率，カッパ係数，F1が高い！

##pp.202
##ナイーブベイズ法の例
##naiveBayes{e1071}, NaiveBayes{klaR}, naive_bayes{naivebayes},
##multinomial_naive_bayes{naivebayes}などがある．
install.packages("naivebayes")
library(naivebayes)
nb1<-multinomial_naive_bayes(as.matrix(train_data[, -58]),
                             train_data[, 58])  #スムージングα=0.5となっている．
pre.nb1<-predict(nb1, as.matrix(test_data[, -58]),
                 type="class")
conM<-table(test_data[, 58], pre.nb1)
confusionMatrix(conM, mode="prec_recall")
##関数multinomial_naive_bayesはtrainの中には実装されていない．

##pp.204
##デフォルト設定のままの例を示す．
##ksvm{kernlab}を用いて，パラメータのチューニングをせず，デフォルトのまま計算する．
ksvm1<-ksvm(type~., data=train_data)
pre.ksvm1<-predict(ksvm1, test_data)
conM<-table(test_data[, 58], pre.ksvm1)
confusionMatrix(conM, mode="prec_recall")

##pp.205-206
##関数trainを用いたチューニングの例
##方法1：パラメータのチューニングはせず，デフォルトのまま計算する．
##カーネルは，ガウスカーネル，シグマは自動推定，C=1である．
fitControl<-trainControl(method="CV", classProbs=TRUE,
                         summaryFunction=multiClassSummary)
tGrid<-expand.grid(sigma=c(1:4)*0.01, C=(1:5)*2)
##このグリッドサーチには，15分前後の時間がかかる．
start_time<-Sys.time()#スタート時点の時間
ksvm2<-train(type~., data=train_data,
             method="svmRadial",
             trControl=fitControl,
             tuneGrid=tGrid
)
end_time<-Sys.time() #終了のときの時間
end_time-start_time #計算にかかった時間

round(ksvm2$results[, c("sigma", "C", "AUC", "Accuracy", "Kappa",
                        "Precision", "Recall", "F1")], 4)
#交差検証に乱数を用いているため，全く同じ結果が得られない．
ksvm2
#ここではsigma = 0.01 and C = 10が最適となった．
plot(ksvm2) #グリッドサーチのグラフを作成する．
pre.ksvm2<-predict(ksvm2, test_data)
conM<-table(test_data[, 58], pre.ksvm2)
confusionMatrix(conM, mode="prec_recall")

##pp.215
##図10.11を作成する例
library(rpart)
data<-"http://mjin.doshisha.ac.jp/data/sb3.csv"
sb3<-read.csv(data, row.names=1)#mac OSの場合：sb3<-read.csv(data, row.names=1, fileEncoding="shift-JIS")
dim(sb3)
install.packages("rpart"); library(rpart)
sb3.rp<-rpart(y~., sb3, minsplit=6) #分類ルールを作成
print(sb3.rp, digits=4)
install.packages("rpart.plot"); library(rpart.plot)
rpart.plot(sb3.rp, digits=4) #図10.10

##pp.216
##spamデータのツリーモデルの例
spam.rp<-rpart(type~., train_data)
pre.rp<-predict(spam.rp, test_data, type="class")
conM<-table(test_data[, 58], pre.rp)
confusionMatrix(conM, mode="prec_recall")
rpart.plot(spam.rp)

##pp.218-219
##AdaBoostによるスパムメールの分類の例
##計算は1分前後必要である．
install.packages("adabag")
library(adabag)
tr.boost<-boosting(type~., data=train_data)
#デフォルトではcoeflearn="Breiman", alpha=(1/2)*ln((1-err)/err)
#引数coeflearn="Freund"の場合は，alpha=ln((1-err)/err)
#引数coeflearn="Zhu"の場合は，alpha=ln((1-err)/err)+ln(nclasses-1)
pre.boost<-predict(tr.boost, test_data[, -58])
conM<-table(test_data[, 58], pre.boost$class)
confusionMatrix(conM, mode="prec_recall")
dotplot(sort(tr.boost$importance),
        scales=list(y=list(cex=0.6))) #変数重要度のグラフを作成

##pp.219-220
##エイダブーストのチューニングの例（計算に約1時間半かかる）
##計算時間は，
##関数trainはエイダブーストの二つのアルゴリズムadaboostとAdaboost.M1を比較する．
##デフォルトでは，繰り返しの計算回数を50, 100, 150回などとしてチューニングすることになっている．
tr.boost<-train(type~., data=train_data,
                method="adaboost",
                trcontrol=trainControl(method="cv")
)

tr.boost
pre.boost<-predict(tr.boost, test_data[, -58])
conM<-table(test_data[, 58], pre.boost)
confusionMatrix(conM, mode="prec_recall")

##pp.223-224
##データspamを用いたランダムフォレストの例
install.packages("randomForest")
library(randomForest)
rf<-randomForest(type~., train_data, ntree=1000, imp=TRUE)
pre.rf<-predict(rf, test_data)
conM<-table(test_data[, 58], pre.rf)
confusionMatrix(conM, mode="prec_recall")
plot(rf) #誤判別率と木の数のグラフを作成
text(400, rf$err.rate[1000, 1]+0.005, "OOB") #ラベル追加
text(400, rf$err.rate[1000, 2]+0.005, "nonspam")
text(400, rf$err.rate[1000, 3]+0.005, "spam")
varImpPlot(rf) #変数の需要度プロット
##関数trainの引数method="rf"を用いて，交差検証や木の数のチューニングなどを行うことも可能である．

##pp.227
##ニューラルネットワークの例
library(nnet)
nnet1<-nnet(type~., size=5, train_data)
pre.nnet<-predict(nnet1, test_data[, -58], type="class")
conM<-table(test_data[, 58], pre.nnet)
confusionMatrix(conM, mode="prec_recall")

##pp.228
##ニューラルネットワークグラフ作成の例
##一つの隠れ層の場合
nnet2<-nnet(type~., size=5, train_data[, c(1:10, 58)])
install.packages("NeuralNetTools")
library(NeuralNetTools)
plotnet(nnet2) #線の太さは，重みの値に比例している．
##二つの隠れ層の場合は，関数neuralnet{Neuralnet}を用いると図10.18のような図を作成することができる．
install.packages("neuralnet"); library(neuralnet)
nnet3<-neuralnet(type~., train_data[c(1:100, 4000:4100), c(1:5, 58)],
                 hidden=c(4, 3))
plot(nnet3)

##pp.229-230
##ニューラルネットワークのチューニングの例（計算に10分前後かかる）
ctrl=trainControl(method="cv", number=10)
t.grid=expand.grid(size=3:10, decay=(0:6)*0.1)
nnet4<-train(type~., data=train_data, method="nnet",
             trControl=ctrl, tuneGrid=t.grid)
nnet4
#中間層のニューロン数は8，減衰重みは0.3のモデルが採用されている．
plot(nnet4)
#グラフで確認できるが，組み合わせによって精度に大きな差があることがわかる．
pre.nnet<-predict(nnet4, test_data[, -58])
conM<-table(test_data[, 58], pre.nnet)
caret::confusionMatrix(conM, mode="prec_recall")

##pp.231-232
##複数分類器の比較（計算に十数分かかる）
install.packages("mlr", dep=TRUE); library(mlr)
library(kernlab); data(spam)
install.packages("kknn", dep=TRUE); library(kknn)
#用いる分類器のリストを作成する．
#次のスクリプトを実行する際，必要なパッケージのインストールを求めるメッセージが出る場合には，
#そのパッケージをインストールしてください．
lrns=list(
  makeLearner("classif.lda", id="lda"),
  makeLearner("classif.kknn", k=3, id="K3_NN"),
  makeLearner("classif.cvglmnet", id="cvglmet"),
  makeLearner("classif.multinom", id="logit"),
  makeLearner("classif.rpart", id="rpart"),
  makeLearner("classif.naiveBayes", id="naiveB"),
  makeLearner("classif.randomForest", id="RF"),
  makeLearner("classif.cforest", id="cForest"),
  makeLearner("classif.randomForestSRC", id="RF_SRC"),
  makeLearner("classif.boosting", id="AdaBoost"),
  makeLearner("classif.C50", id="C50"),
  makeLearner("classif.ksvm", kernel="polydot", id="svmPoly"),
  makeLearner("classif.ksvm", kernel="rbfdot", id="svmRadial"),
  makeLearner("classif.h2o.gbm", id="h2o_gbm"),
  makeLearner("classif.xgboost", id="XGBoost"),
  makeLearner("classif.h2o.deeplearning", id="h2o_deep")
)
#分析のデータ形式をパッケージ用に作成しなおす．
task<-makeClassifTask(data=spam, target="type")
#以下は5分割交差確認を行う
rdesc=makeResampleDesc(method="CV", iters=5)
res<-benchmark(lrns, task, rdesc, measures=list(acc), show.info=FALSE) #計算
#以下は10分割交差確認iters=10の結果である．
#plotBMRBoxplots(res)          #箱ひげ図を作成する．
Perf<-getBMRPerformances(res, as.df=TRUE) #CVの正解率を渡す．
boxplot(Perf[, 4]~Perf[, 2], las=2, xlab="", ylab="正解率")
grid()
getBMRAggrPerformances(res, as.df=TRUE) #正解率の平均値を返す．

##pp.223-224
##10人の小説の形態素データを用いた複数分類器比較（計算に約7分かかる）
path<-"http://mjin.doshisha.ac.jp/data/sakka10.csv"
sakka10<-read.csv(path, row.names=1, fileEncoding="shift-JIS") #データの読み込み
##データの変数は記号V2，V3のようになっている．
##対応する形態素ファイルはsakka10Var.csvとしてアップしている．
lrns=list(
  makeLearner("classif.kknn", k=3, id="KS_NN"),
  makeLearner("classif.cvglmnet", id="cvglmet"),
  makeLearner("classif.rpart", id="rpart"),
  makeLearner("classif.naiveBayes", id="naiveB"),
  makeLearner("classif.randomForest", id="RF"),
  makeLearner("classif.cforest", id="cForest"),
  makeLearner("classif.randomForestSRC", id="RF_SRC"),
  makeLearner("classif.boosting", id="AdaBoost"),
  makeLearner("classif.C50", id="C50"),
  makeLearner("classif.ksvm", kernel="polydot", id="svmPoly"),
  makeLearner("classif.ksvm", kernel="rbfdot", id="svmRadial"),
  makeLearner("classif.h2o.gbm", id="h2o_gbm"),
  makeLearner("classif.xgboost", id="XGBoost"),
  makeLearner("classif.h2o.deeplearning", id="h2o_deep")
)
task<-makeClassifTask(data=sakka10[, 1:30], target="authors")
#5分割交差確認を行う
rdesc=makeResampleDesc(method="CV", iters=5)
res2=benchmark(lrns, task, rdesc, measures=list(acc), show.info=FALSE) #計算
#以下は10分割交差確認iters=10の結果である．
Perf<-getBMRPerformances(res2, as.df=TRUE)
boxplot(Perf[, 4]~Perf[, 2], las=2, xlab="", ylab="正解率")
grid()
getBMRAggrPerformances(res2, as.df=TRUE)

##pp.236
##5つの強分類器によるアンサンブル学習（計算に約8分かかる）
install.packages("caretEnsemble")
library(caretEnsemble)
library(caret)
set.seed(0)
ensList<-c("ada", "C5.0", "rf", "xgbTree")
trCon<-trainControl(method="repeatedcv", number=5, repeats=1,
                    savePredictions="final", classProbs=TRUE)
mod<-caretList(type~., data=spam,
               methodList=ensList, trControl=trCon)
##パッケージのインストールを求めるメッセージが出たら，yesを入力してください．
(res<-caretEnsemble(mod))
plot(res)