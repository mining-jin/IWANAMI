#スパムメールのデータセット
install.packages("kernlab")
library(kernlab)
data(spam)
dim(spam)
str(spam)
##変数typeがspamであるかnonspamであるかを示す因子データである.

##学習と予測のプロセスを説明するため，データセットの中から10分の1をランダムに抽出してテストデータとし，それ以外を学習データとする．
m<-round(nrow(spam)/10)     #10分の1の数を計算する．
set.seed(1)                 #乱数の種を指定する．
sp<-sample(1:nrow(spam), m) #標本の行の番号をサンプリングする．
train_data<-spam[-sp,]      #学習用データを作成する．
test_data<-spam[sp,]        #テスト用データを作成する．

##knnを用いたスパムメールの分類の例
##kNN法を用いるためにはまずkを指定しなければならない．
##とりあえずk=3で行ってみよう．
library(class)
library(e1071)
library(caret)
knn.md1<-knn(train_data[,-58], test_data[,-58],
             train_data[,58], k=3) #学習データを用いてテストを行う.
conM<-table(test_data[,58], knn.md1)#混同表を作成する．
caret::confusionMatrix(conM, mode = "prec_recall")#混同表の統計量を返す．

spam[1:2, c(1:3, 54:57)]

#データの標準化と一部変数の削除
##データを標準化して分類を行う
Sdata<-scale(train_data[,-58])
train1<-data.frame(Sdata, type=train_data$type)
Stest<-scale(test_data[,-58])
test1<-data.frame(Stest, type=test_data$type)
knn.md2<-knn(train1[,-58], test1[,-58], train1[,58], k=3)
conM<-table(test_data[,58], knn.md2)
caret::confusionMatrix(conM, mode="prec_recall")

##変数1~54までを用いて分類を行う
train_data2<-train_data[,-c(54:57)]
test_data2<-test_data[,-c(54:57)]
knn.md3<-knn(train_data2[,1:53], test_data2[,1:53],          
             train_data2[,54], k=3)
conM<-table(test_data2[,54], knn.md3)
caret::confusionMatrix(conM, mode = "prec_recall")

#k近傍法を用いたスパム・ノンスパム
install.packages("caret", dep = TRUE)
library(caret)
##train{caret}を用いてkについてチューニングを行う．
knn.md4<-train(
  type~.,
  data = train_data2,
  method = "knn",
  tuneGrid = expand.grid(k = c(1:10)),
  preProcess = c('center', 'scale'),
  trControl = trainControl(method = "CV", classProbs = TRUE,
              summaryFunction = multiClassSummary)
              )
##計算された結果はknn.md4に保存され，評価指標の項目は次のコマンドで確認できる．knn.md4を実行するとk=1~10の以下に示す指標の値を返し，最後に推奨するkの値を返す．このkは正解率(Accuracy)に基づいて判断している．用いたデータではk=1が推奨されている．
knn.md4
#<前略>

plot(knn.md4) #グラフを作成して考察することもできる．
colnames(knn.md4$results)

##主な学習結果を次に返す．
round(knn.md4$results[,c("k", "AUC", "Accuracy", "Kappa", "Precision", "Recall", "F1")], 3)
#<後略>
##テストデータを用いた予測は関数predictを用いる．
pre.knn<-predict(knn.md4, test_data2)
conM<-table(test_data2[,54], pre.knn)
confusionMatrix(conM, mode = "prec_recall")
#<後略>
##F1はk=1の場合がk=3の場合より高い．
##変数1~54を用いる正解率，F1値はわずかではあるが向上している．
##AUCの計算auc{ModelMetrics}
ModelMetrics::auc(pre_spam.knn, test_data[,58])

#線形判別分析法による分析結果を次に示す.
##方法1:関数lad{MASS}を用いる．変数54~57を取り除いたtrain_data2, test_data2を用いることにする．
library(MASS)
lda.mod1<-lda(type~., data = train_data2)
##作成したモデルの評価指標を確認してみよう．
pre.mod1<-predict(lda.mod1)#学習データの判別結果
conM<-table(train_data2[,54], pre.mod1$class)#学習データの判別結果の混同表
confusionMatrix(conM, mode = "prec_recall")
#<後略>
##学習モデルを用いた予測
pre.mod2<-predict(lda.mod1, test_data2)
conM<-table(test_data2[,54], pre.mod2$class)
confusionMatrix(conM, mode = "prec_recall")
#<後略>

##方法2:関数train{caret}を用いる．
lda.mod2<-train(type~., data = train_data2, 
                metric = "ROC",
                method = "lda",
                preProcess = c('center', 'scale'),
                trControl = trainControl(method = "CV", classProbs = TRUE,
                                         summaryFunction = multiClassSummary)
)
round(lda.mod2$results[,c("AUC", "Accuracy", "Kappa", 
                          "Precision", "Recall", "F1")], 4)
##学習モデルを用いた予測
pre.mod3<-predict(lda.mod2, test_data2)
conM<-table(test_data2[,54], pre.mod3)
##結果はlda{MASS}と同じである．

#判別関数の係数の棒グラフの作成
##上記の関数trainでは係数を抜き出すことが難しいため，lda{MASS}を用いる．
library(MASS)
spam.lda2<-lda(type~., data = spam)
##求めた判別関数の係数はspam.lda2$scalingに保存している．
coef1<-spam.lda2$scaling
coef<-coef1[sort.list(coef1, dec = TRUE),]
par(mar=c(4, 10, 2, 2))
barplot(coef[1:15, 43:57], las=2, horiz=T, cex.names=0.9)
text(-0.5, 10, "スパムメール\nの特徴要素", cex=1.5)
text(-0.5, 25, "ノンスパムメール\nの特徴要素", cex=1.5)

##二項ロジスティック回帰・判別に関して複数のパッケージがあるが，多項ロジスティック判別に関してはmultinom(nnet)が広く知られている．関数multinomには，交差検証法がない．
library(nnet)
mu1<-multinom(type~., data = train_data)
coef(mu1)#係数を返す
##主な判別係数の棒グラフを作成する
coef1<-sort(coef(mu1)[-1])#係数を小さい順に並び替える．
coef2<-coef1[c(1:15, 43:57)]#上・下位15個を抜き出す．
par(mar=c(4, 10, 2, 2))
barplot(coef2, horiz = T, las = 2, col = c(rep(3, 15), rep(4, 15)))
##データの判別
pre.mu1<-predict(mu1)
conM<-table(train_data2[,54], pre.mu1)
confusionMatrix(conM, mode = "prec_recall")

##テストデータの判別
pre.mu2<-predict(mu1, test_data2)
conM<-table(test_data2[,54], pre.mu2)
confusionMatrix(conM, mode = "prec_recall")

#<後略>
##交差検証法を行う場合は，関数trainを用いることができる．また，重みを求める際に，値が大きくなりすぎないようなペナルティをかけている．このペナルティをどれぐらいにするかはデータに依存する．関数trainではこれをチューニングできるように組み込んでいる．
mu2<-train(type~., data = train_data2,
           method = "multinom",
           preProcess = c('center', 'scale'),
           trControl = trainControl(method = "CV", classProbs = TRUE,
                                    summaryFunction = multiClassSummary)
)
mu2 #計算結果を返す．
#<前略>
#Accuracy was used to select the optimal model using the largest value. The value for the model was decay = 1e-04.
#ペナルティの値はdecay = 1e-04を推奨している．

round(mu2$results[,c("decay", "AUC", "Accuracy", "Kappa", "Precision", "Recall", "F1")], 4)
##テストデータを用いた予測は関数predictを用いる
pre.mu2<-predict(mu2, test_data2[,-54])
##混同行列および正解率，Kappa係数などを返す
conM<-table(test_data2[,54], pre.mu2)
confusionMatrix(conM, mode = "prec_recall")
pre.mu2<-predict(mu2, test_data2[,-54])
conM<-table(test_data2[,54], pre.mu2)
confusionMatrix(conM, mode = "prec_recall")

#<後略>
##適合率(precision)，再現率(recall)，F1値(F_meas)を計算する．
##結果から分かるように，kNN法と線形判別よりよい！

##ナイーブベイズ法の例
##naiveBayes{e1071}, NaiveBayes{klaR}, naive_bayes{naivebayes},
##multinomial_naive_bayes{naivebayes}などがある.
library(naivebayes)
nb1<-multinomial_naive_bayes(as.matrix(train_data2[,-54]),
                             train_data2[,54])#スムージングα=0.5となっている．
pre.nb1<-predict(nb1, as.matrix(test_data2[,-54]),
                 type="class")
conM<-table(test_data2[,54], pre.nb1)
confusionMatrix(conM, mode = "prec_recall")
##関数multinomial_naive_bayesはtrainの中には実装されていない．

#デフォルト設定のままの例を示す．
##ksvm{kernlab}を用いて，パラメータのチューニングはせず，デフォルトのまま計算する．
ksvm1<-ksvm(type~., data = train_data2)
pre.ksvm1<-predict(ksvm1, test_data2)
conM<-table(test_data2[,54], pre.ksvm1)
confusionMatrix(conM, mode = "prec_recall")
#後略

#関数trainを用いたチューニングの例
##方法1:パラメータのチューニングはせず，デフォルトのまま計算する．
##カーネルは，ガウシアン，シグマは自動推定，C=1である．
ficControl<-trainControl(method = "CV", classProbs = TRUE,
                           summaryFunction = multiClassSummary)
tGrid<-expand.grid(sigma = c(1:4)*0.01, C = 1*5)
##このグリッドサーチには，用いたマシンでは14分かかった．
start_time <- Sys.time()  #スタート時点の時間
ksvm2 <- train(type~., data = train_data, 
               method = "svmRadial", 
               trControl = fitControl,
               tuneGrid = tGrid)
end_time<-Sys.time() #終了のときの時間
end_tim - start_time #計算にかかった時間
round(ksvm2$results[,c("sigma", "C", "AUC", "Accuracy", "Kappa", 
                       "Precision", "Recall", "F1")], 4)

#<前略>
#<後略>
#交差検証に乱数を用いているため，全く同じ結果が得られない．
ksvm2
#<前略>
#ここではsigma = 0.02 and C = 5が最適となった．
plot(ksvm2) #グリッドサーチのグラフを作成する．
pre.ksvm2<-predict(ksvm2, test_data2)
conM<-table(test_data2[,54], pre.ksvm2)
confusionMatrix(conM, mode = "prec_recall")
#<後略>

#図11.10を作成する例
library(rpart)
data<-"http://mjin.doshisha.ac.jp/iwanami/data/sb3.csv"
sb3<-read.csv(data, row.names = 1)
dim(sb3)
sb3.rp<-rpart(y~., sb3, minsplit = 6) #分類ルールを作成
print(sb3.rp, digits = 4)
library(rpart.plot)
rpart.plot(sb3.rp, digits = 4) #図11.10

#spamデータのツリーモデルの例
spam.rp<-rpart(type~., train_data2)
pre.rp<-predict(spam.rp, test_data2, type = "class")
conM<-table(test_data2[,54], pre.rp)
caret::confusionMatrix(conM, mode = "prec_recall")
rpart.plot(spam.rp)

#AdaBoostによるスパムメールの分類の例
install.packages("adabag")
library(adabag)
tr.toost<-boosting(type~., data = train_data)
#デフォルトではcoeflearn = 'Breiman', alpha = (1/2)*ln((1-err)/err)
#coeflearn = 'Freund', alpha = ln((1-err)/err)
#coeflearn = 'Zhu', alpha = ln((1-err)/err)+ln(nclasses-1)
pre.boost<-predict(tr.toost, test_data[,-58])
conM<-table(test_data[,58], pre.boost$class)
caret::confusionMatrix(conM, mode = "prec_recall")
dotplot(sort(tr.toost$importance), 
        scales = list(y = list(cex = 0.6))) #変数重要度のグラフ作成

##エイダブーストのチューニングの例
##関数trainはエイダブーストの2つのアルゴリズムadaboostとAdaboost.M1を比較する．デフォルトでは，繰り返しの計算回数を50, 100, 150回チューニングすることになっている．
tr.boost<-train(type~., data = train_data2, 
                method = "adaboost",
                trcontrol = trainControl(method = "cv")
)
tr.boost
pre.boost<-predict(tr.toost, test_data[,-58])
conM<-table(test_data[,58], pre.boost$class)
caret::confusionMatrix(conM, mode = "prec_recall")
#<後略>

##データspamを用いたランダムフォレストの例
library(randomForest)
rf<-randomForest(type~., train_data2, ntree=1000, imp=TRUE)
pre.rf<-predict(rf, test_data2)
conM<-table(test_data2[,54], pre.rf)
caret::confusionMatrix(conM, mode = "pre_recall")
plot(rf)  #誤判別率と木の数のグラフを作成
text(400, rf$err.rate[1000,1]+0.005, "OOB") #ラベル追加
text(400, rf$err.rate[1000,2]+0.005, "nonspam")
text(400, rf$err.rate[1000,3]+0.005, "spam")
varImpPlot(rf) #変数の重要度をプロット
##関数trainの引数method="rf"を用いて，交差検証や木の数のチューニングなどを行うことも可能である．

#ニューラルネットワークの例
library(nnet)
nnet1<-nnet(type~., size=5, train_data)
pre.nnet<-predict(nnet1, test_data[,-58], type="class")
conM<-table(test_data[,58], pre.nnet)
caret::confusionMatrix(conM, mode="prec_recall")

#ニューラルネットワークグラフ作成の例
##1つの隠れ層の場合
nnet2<-nnet(type~., size=5, train_data[,c(1:10, 58)])
library(NeuralNetTools)
plotnet(nnet2)
##2つの隠れ層の場合の例（図11.17の作成）
library(neuralnet)
temp<-train_data[c(1:100, 4000:4100), c(1:5, 58)]
net1<-neuralnet(type~., temp.hidden = c(4, 3))
plot(net1)


#ニューラルネットワークのチューニングの例（計算に10分前後が必要）
ctrl = trainControl(method = "cv", number = 10)
t.grid = expand.grid(size = 3:10, decay = (0:6)*0.1)
nnet4 <- train(type~., data = train_data, method = "nnet",
               trControl = ctrl, tuneGrid = t.grid)
nnet4
#中間層のニューロン数は8，減衰重みは0.3のモデルが採用されている．
plot(nnet4)
pre.nnet<-predict(nnet4, test_data[,-58])
conM<-table(test_data[,58], pre.nnet)
caret::confusionMatrix(conM, mode = "prec_recall")